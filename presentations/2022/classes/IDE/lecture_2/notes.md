i wanted you all to be thinking about these very concrete examples of dilemmas and issues that arise. when we talk about data ethics, we seem to be talking about nebulous things, or maybe thinking about this as something that was a problem in the past, but "isn't a problem now". but, as you've seen, that's not the case.

you may someday be working on a dating app and the data retention policies could affect the lives of people thousands of miles away. or you may be involved in the design of a product that interacts with vulnerable people in the middle of a crisis or otherwise vulnerable, and you'll need to think more carefully about the circumstances surrounding the person who says they accept or they consent when you present them with a form.

you're going to be in a position of relative power if you're working at any of these companies - in some sense these will be the platforms and spaces that you "own" and the users will just be "tenants" who exist in the space thanks to your consent. whether it's legal or illegal to track users with dubious affirmations of consent may shift according to surprisingly fickle things, like political campaigns that go just right or just wrong. for instance, does *owning* property mean that you can assert your rights over someone else as long as they're in that space? which rights, precisely? is there a limit to that?



these articles also point to failures to be good to others.in some cases they point to individual failures; in others, to structural and organizational failures.

for example: Kosinski and his co-authors have claimed over the years that the point of these systems that they publish - gaydar, and others - is to show how readily you can weaponize these tools. ethicists have pointed out that it's not clear how that argument tracks:

is the point to show that you can accomplish *good* results? because 1) these aren't very good; and 2) these are photos taken (without consent) from a dating platform. which is... sort of weird? people will present themselves fairly intentionally on a dating platform in ways that training systems will conflate with everything else.

is the point to show that you can accomplish shitty results? because... that's obvious. the paper didn't claim that the results were *bad*; if it did, no reviewer would have accepted it.

is the point to show that a malicious actor with power might use this system to oppress LGBTQ people? as we saw in that middle east article, police in oppressive states will use whatever flimsy evidence they find to justify violence. this system doesn't change the game - it just offers a poor warrant to use this tech because "it's been published in journals"