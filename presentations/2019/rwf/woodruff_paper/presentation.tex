\documentclass[aspectratio=169,12pt]{beamer} % or 14 or 17 or 20

\usepackage{tikz,pgf,lmodern,textpos,hyperref,graphicx,booktabs,appendixnumberbeamer}
\usepackage{pgfcalendar,pgfornament,svg,subfiles,chronosys,cancel,xcolor,color,nth}
\usepackage[outline]{contour}
\usepackage{datenumber,xparse,fp}
\usetikzlibrary{arrows,automata}
\usepackage[citestyle=authoryear-comp,backend=bibtex]{biblatex}
\usepackage[export]{adjustbox}
\usepackage[en-US]{datetime2}
\bibliography{references}

% \usetheme[numbering=none]{metropolis} % ready to go?
\usetheme[]{metropolis}

\beamertemplatenavigationsymbolsempty
\definecolor{stanfordRed}{HTML}{8C1515}
\definecolor{metroBackground}{RGB}{250,250,250}

\DeclareCiteCommand{\eventcite}{}{\chronosevent{\thefield{year}}{\printnames{labelname}}}{}{}


\definecolor{Orange}{HTML}{E98125}
\definecolor{Blue}{HTML}{0645AD}
\hypersetup{colorlinks,linkcolor=,urlcolor=Blue}

\definecolor{PineGreen}{HTML}{008800}
\definecolor{Red}{HTML}{FF0000}
\definecolor{Blue}{HTML}{0000FF}
\definecolor{JokeGreen}{HTML}{00C953}
\newcommand{\msb}[1]{{\color{PineGreen}[MSB: #1]}}
\newcommand{\ali}[1]{{\color{Red}[al2: #1]}}

\newenvironment{mystepwiseitemize}{\begin{itemize}[<+-| alert@+>]}{\end{itemize}}
% Theme colors are derived from these two elements
\setbeamercolor{alerted text}{fg=Orange}
\setsansfont[BoldFont={Source Sans Pro Bold},
              Numbers={OldStyle}]{Source Sans Pro}
\setmainfont[BoldFont={Source Serif Pro Semibold},
              Numbers={OldStyle}]{Source Serif Pro}
\setmonofont{Source Code Pro}
\setbeamercolor{institute in head/foot}{fg=stanfordRed}
\setbeamercovered{transparent}
\setbeamercovered{again covered={\opaqueness<1->{15}}}

\title{\textit{[Allison Woodruff on] Algorithmic Fairness}}
% \metroset{titleformat=smallcaps}
\contourlength{0.1pt}
\contournumber{10}
\author{{Ali Alkhatib}\\
\href{mailto:ali.alkhatib@cs.stanford.edu}{ali.alkhatib@cs.stanford.edu} ||
         \href{http://twitter.com/_alialkhatib}{@\_alialkhatib}}

\institute[Stanford]{reading with friends}
\date{\today}

\hypersetup{
  colorlinks = true,
  % linkcolor = blue,
  citecolor = blue
}


\newcommand{\onlyinsubfile}[1]{#1}
\newcommand{\notinsubfile}[1]{}
\begin{document}
\renewcommand{\onlyinsubfile}[1]{}
\renewcommand{\notinsubfile}[1]{#1}

\begin{frame}
\titlepage
\end{frame}
% \setbeamercovered{transparent}

% \subfile{ethical_schools}
\begin{frame}{There's bias!}

algorithms aren't objective [4,10,18,33--35,38,46,64]

{\footnotesize (literally the citation for that statement. there was an en--dash)}
\end{frame}

\begin{frame}{the study (method)}

\textbf{Workshop as method}

``argument against assuming a single correct understanding of science and technology''

related history to participatory design


\end{frame}



\begin{frame}{the study (setup)}
the details
\begin{itemize}
  \item workshops with communities in the bay area
  \item july--september 2016
  \item 44 adults
  \item marginalized groups (by SES or race)
  \begin{itemize}
    \item 2x for SES
    \item 1x for AA women
    \item 1x for AA or mixed race men \& women
  \end{itemize}
\end{itemize}

asking groups what they'd do in an instance of \alert{algorithmic unfairness}
\end{frame}

\begin{frame}{``unfamiliar but not unfathomable''}
  
  people have had experiences of unfair treatment and could relate their experiences to that

\textit{discrimination} {\footnotesize (e.g. ``driving while Black'')}

\textit{prior awareness} {\footnotesize (e.g. low--income credit card offers)}

\textit{reactions} {\footnotesize (strongly negative)}

% \textit{prior awareness} {\footnotesize (e.g. low--income credit card offers)}


\end{frame}


\begin{frame}{results}

things feel a little ``all over the place''

\begin{itemize}
  \item feelings that it's unfair
  \item frustration that it's a machine and should be making decisions based on information (implicitly [more] objective)
  \item small mistakes are okay {\footnotesize (``It sounds fine to me \dots I don't expect perfection, of course'')}
\end{itemize}


\end{frame}

\begin{frame}{accountability}
    Who should be accountable?

    \alert{the programmers}, according to Woodruff's interviews ``not necessarily because they thought programmers were ill--intended, but rather because their perception was that \dots [predominantly white males] do not understand the perspective of more diverse users.''

    ``Algorithmic bias may not be intentional, but it is negligent.''

    {\footnotesize see how that quote came back?}


\end{frame}

\begin{frame}{complications}

is bias a reflection of society?

should companies get involved --- is this a free speech issue?

is it even technically feasible?

\end{frame}

\begin{frame}{Curation}
    
participants hold search engines to the standards of journalists (removing crap, etc\dots)

{\footnotesize ``I would only allow what is a actual fact. I don't need to know your cousin, your momma, said this that and the other, just include [\dots] the facts.''}

\end{frame}


\begin{frame}{Design implications?/discussion}

\begin{enumerate}
  \item include fairness as a value in product design and development
  \item design user studies that accommodate diverse perspectives, and include members of traditionally marginalized populations in user testing
  \item engage with community groups and advocates to collaboratively develop solutions
\end{enumerate}

\end{frame}

% \begin{frame}[standout]
%     Legislation should be a safety net,\\
%     not an ethical baseline.
% \end{frame}

% \subfile{roadmap}


% \subfile{data}
% \subfile{hypermap}
% \subfile{speech}

% \subfile{more_stuff}

\subfile{contact}



% \begin{frame}[allowframebreaks]{References}
%   \printbibliography{}
% \end{frame}

\end{document} 