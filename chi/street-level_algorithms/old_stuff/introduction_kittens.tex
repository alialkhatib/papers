\documentclass[main]{subfiles}

\begin{document}

\section{Introduction}\label{sec:introduction}

\topic{Digitally mediated systems often bely the amount of thought that went into them.}
Whether we users are hailing a taxi,
or searching for information about a business, 
or reading about current events ---
some system has classified and predetermined much of what we see, and
indeed much of what the system does with --- and to --- us as we navigate the world through that system.

\topic{But these systems fail ---
sometimes they fail quietly; sometimes they fail loudly.}
Sometimes these systems fail by gouging us in moments of desperation ---
when people desperately try to escape the site of a shooting, 
or when our personal phones are nearly depleted.
Sometimes these systems fail by outing people for their sexuality (Facebook),
or by discouraging people from talking about it (YouTube).
Sometimes they fail by classifying pictures of people of color as animals (Google),
or by making prejudiced judgments about bail and sentencing,
informed by crime statistics but not taught to reflect on that data (Sharad Goel etc\dots).

\topic{In all of these cases, AI systems fail in inhumane ways.}
% That is, they make decisions absent of human qualities such as compassion.
They fail to recognize the underlying purpose of the tasks to which they're set,
let alone the overarching goal of the endeavor.
They fail to demonstrate compassion.
Optimizing against recidivism without considering the racially charged history of the criminal justice system;
attempting to maximize advertising revenue without recognizing the chilling effect of demonetizing important controversial work in favor of promoting the normative;
etc\dots
% Ultimately, they fail in that they have no capacity for compassion.

\topic{Work has gone into studying the cases of failure that emerge, but not necessarily into thinking about these systems --- and the ways they fail --- in a collective context.} 
Researchers have documented many of the ways that digitally mediated systems fail users~\cite{takingAHITMcInnis,turkopticon,crowdcollab};
others have written about how people work \textit{around} those systems in times of failure~\cite{uberAlgorithm,irani2015cultural,Jhaver:2018:AAC:3173574.3173995}.
Ultimately, this body of work focuses on \textit{instances} of failure, rather than the common origins of these types of failure.
\citeauthor{uberAlgorithm} write about the subtle nuances of resetting driver availability to influence the distance from which they're hailed~\cite{uberAlgorithm};
\citeauthor{Jhaver:2018:AAC:3173574.3173995} discuss the myriad ways Airbnb hosts perform a digital dance to endear themselves to black box algorithmic systems~\cite{Jhaver:2018:AAC:3173574.3173995}.





\topic{What we hope to offer in this paper is a reliable, consistent way of thinking about a pernicious issue in HCI
--- algorithmic bias ---
that offers evaluable hypotheses to existing questions,
suggests future research agendas, and most importantly
provides a vocabulary for reasoning about AI systems with which we can accept, reject, or qualify already--developed theory.}
Here's how we're going to tackle this:
\begin{enumerate}
  \item Talk about what we mean when we talk about bureaucracies: Weberian bureaucratic organizations
  \item Weberian bureaucracies describe a model of organizations that's somewhat idealized, which describes the relationship people have formed with online systems
  \item 
\end{enumerate}






\onlyinsubfile{
  We hope to offer a way of thinking about these modes of failure that's at once familiar as well as capable of providing a new way of thinking about this area.
  While the previously mentioned work has illuminated their corresponding domains, we hope to situate


  Not having a more general way to frame this area of work
  --- lacking powerful analytical tools to make sense of the boundaries of these problems, to inform research questions, and to provide a vocabulary for answering those questions ---
  stymies meaningful work toward understanding how and why digitally mediated systems fail in spectacular, harmful ways;
  perhaps as importantly, it deprives us of valuable existing work that speaks substantively about our blahhhhhhhhhhhhhh
}


% \topic{But nature, ah, finds a way}

% Sometimes they fail in ways that benefit us; sometimes they fail to our harm.
% Sometimes they fail 


% \topic{As a field,
% we've been documenting and reflecting on \textit{instances} of failure in artificially intelligent systems, but
% we haven't been taking a big step back to reflect on the origins of these problems, and
% how these origins fit into existing \textbf{sociolological} theory.}
% In the same way that \citeauthor{postcolonialComputing} offer a potential way of thinking about ICT4D computing
% --- through the lens of \textit{postcolonialism} ---
% we're going to try and suggest a way of thinking about algorithmically intelligent systems which
% classify, label, and otherwise ``deal'' with data to inform decisions about what to do with people~\cite{postcolonialComputing}.
% That way of thinking about AI systems will borrow heavily from
% literature about bureaucratic organizations for a number of reasons that we'll discuss.

% \topic{In this paper, we'll reflect on a few problems that have come up in social computing and
% point out ways that the research into bureaucracies helps either frame or indeed inform the question.}
% In some cases, we'll be able to provide the basic framework for an answer to the problem at hand;
% in most cases, we can offer a vocabulary that brings to the surface
% myriad dimensions and characteristics that, we argue, will prove to be important in finding answers.

% \topic{There are a few characteristics of bureaucratic organizations that make them appealing for thinking about algorithmic systems.}
% Algorithmic systems follow processes and are reasonably predictable.
% AIs in particular are designed to optimize for certain \textbf{tasks} which are in service to higher level \textbf{goals}.
% To many experts, one of the major bottlenecks in AI systems is the acquisition of high--quality data.







% \topic{Researchers have taken an interest in some of the myriad ways that people deal with artificial intelligence systems.}
% \begin{itemize}
%   \item Airbnb hosts doing all sorts of weird stuff to get boosts in the search results~\cite{Jhaver:2018:AAC:3173574.3173995}
%   \item Uber drivers toggling to get better radii~\cite{uberAlgorithm}
%   \item algorithmic bail-setting~\cite{jung2017simple}
%   \item etc\dots
% \end{itemize}
% This is causing an enormous amount of stress in the form of
% \begin{itemize}
%   \item YouTube drama
%   \item protests among Uber/Lyft/other drivers
%   \item others?
% \end{itemize}
% Individually, these papers start to illuminate very localized areas of research.
% We're beginning to get a sense of the various ways that
% Airbnb hosts, or Uber \& Lyft drivers, or YouTubers, or prison inmates
% all deal with decisions being made about them through the use of algorithms.



% \topic{But these works are etching the outlines of what may prove to be a much broader territory
% --- a field of scholarship encompassing AI \& ethics, and
% converging on a question of profound importance.}

% \textsc{Are AI systems destined to be adversaries of people,
% circumvented by the targets of these systems who can frustrate AI systems,
% and resented by those who cannot?}
% Put another way, what role will AI systems have in our lives --- or will we have in theirs?

% \topic{We evaluate AI systems for problematic outcomes in a number of ways.}
% One of the more common ways that we evaluate AI systems is by seeing how often
% (and to what extent) people work around the system.
% It represents a failure of sorts on the part of Uber's matching algorithm that
% drivers toggle their availability to avoid its inevitably growing radius~\cite{uberAlgorithm}.




\onlyinsubfile{
  \bibliographystyle{ACM-Reference-Format}
  \bibliography{references}
}
\end{document}
